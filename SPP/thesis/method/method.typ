= 2. Method
The applied method for this thesis is Design Science Research (DSR). DSR was chosen due to its natural fit for projects involved in creation of a software artifact. It is described by vom Brocke et al @introduction-to-design-research as a paradigm that seeks to enhance knowledge through the creation of an innovative artifacts. They further explain that the aim of DSR is to generate knowledge about how things can and should be constructed, knowledge that is referred to as design knowledge within the DSR paradigm.


== 2.1 Research project
The company Neurawave @neurawave presented a need for collecting health metrics that could be used for migraine prediction using machine learning. One of the key requirements was that the data collection mechanism had to be integrated into their existing cross-platform mobile application. We began by clearly defining the problem and concluded that the Design Science Research methodology would be the most appropriate method for addressing it. In this work, we follow the DSR methodology outlined by Peffers et al @design-science-research-methodology. 

The next step in the project involved defining the objectives of a solution, which had to be closely aligned with the problem identified and the needs expressed by the stakeholders. During this phase, we will also conduct a literature review to gather insights into existing solutions and to better understand the current state of the problem domain. 

Subsequently, we will proceed to develop the artifact, in our case the data collection component for mobile platforms. The development will be carried out in an iterative manner, including both the creation of the software and the refinement of its functionality based on the defined objectives.
Once the artifact has been developed, we will demonstrate its capabilities in addressing aspects of the defined problem through experimentation or simulation. This will be followed by rigorous evaluation of how well the artifact meets the objectives, likely by comparing the implemented functionality with the stakeholder-defined goals.

== 2.2 Research methods
We began our research project by conducting open-ended interviews with the founders of Neurawave @neurawave. Open-ended interviewing allows for a flexible, free-flowing conversation and is considered a qualitative method of data collection @interviewing-as-a-data-collection-method. This method was chosen because the stakeholders possessed significantly more domain knowledge than us, making them essential in framing the problem accurately. As described by Alshenqeeti @interviewing-as-a-data-collection-method, the purpose of open-ended interviews is to "broaden the scope of understanding of investigated phenomena". We believed this approach would help us build a deeper understanding of both stakeholder needs and the problem domain. 

Open-ended interviews fall within the broader category of qualitative methods, which are generally holistic and aimed at answering "what" questions. In contrast, structured interviews are more quantitative, relying on closed-ended questions, such as those with yes/no responses @interviewing-as-a-data-collection-method. As Lakshman et al. @quantitative-vs-qualitative-research-methods explain, quantitative methods focus on examining the effect of an independent variable on a dependent variable in a measurable, numerical way. However, at this early stage in the project, a qualitative approach was better suited to developing our understanding and framing our objectives. 

Following the interviews, we conducted litterature research to expand our contextual understanding of the problem area. Literature research involves exploring a broad body of work related to a topic and is typically less rigid than a systematic literature review @literature-reviews-vs-systematic-reviews. A systematic review, by contrast, targets a specific research question and is intended to gather empirical evidence to support conclusions. We chose a narrative-style literature review to ground our work theoretically and better understand the current landscape of data collection for health-related machine learning applications. 

Alternative approaches, such as expert interviews could also have been employed to gather real-world insights. As described by DÃ¶ringer @the-problem-centered-expert-interview, expert interviews are valuable for problem-centered exploration and knowledge gathering. However, due to the time and resource constraints, this method was not feasible within the scope of this thesis. Nonetheless, it represents a promising avenue for future research and validation.

During the design and development phase, we followed the artifact creation process outlined in the Design Science Research methodology. While this is not an empirical method in the classical sense, it is a core research activity in DSR, where existing knowledge and stakeholder input are synthesized into a functional solution. We began by defining application requirements that map directly to stakeholder requirements and then iteratively developed the plugin aimed at fulfilling those needs. No specific structured development framework as followed, as our team had prior experience in collaborative software development.

To evaluate the developed solution, we will use experimentation as the primary method of validating functionality. According to Basili et al. @experimentation-in-software-engineering, experimentation is an iterative process of hypothesizing and testing. In our case, this involves defining (or redefining) software requirements, implementing them (the hypothesis), and verifying wether those requirements are fulfilled (the test).

Additionally, we will perform validation to ensure tha the plugin's software requirements align with the original stakeholder expectation @the-role-of-software-verification. As an alternative to experimentation, we considered survey-based research to gather stakeholder opinions on desired functionality. However, we ultimately decided against this due to our limited timeframe. We also believed that the iterative loop supported by experimentation would be hindered by the time required to create, distribute and analyze a survey. In our context, experimentation offers more immediate feedback and supports rapid iteration, which we viewed as essential for effective development.

#bibliography("refs.yml")